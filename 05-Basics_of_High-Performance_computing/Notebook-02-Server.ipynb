{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPI tutorial\n",
    "\n",
    "This notebook comes in two pieces: server-side (this one) and client-side ([Client.ipynb](Notebook-02-Client.ipynb)). The two notebooks are meant to be executed side-by-side.\n",
    "\n",
    "## Disclaimer\n",
    "\n",
    "The approach used in this tutorial, i.e. using two notebooks connected to each other, it is not the standard nor the suggested approach for using MPI. Usually one would have a python script `script.py` that is run on `N` processes via\n",
    "\n",
    "```\n",
    "mpirun -n N python script.py\n",
    "```\n",
    "\n",
    "as in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mpi_example.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "\n",
    "print(f\"Hello from rank {comm.rank}/{comm.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mpirun -n 8 python mpi_example.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server-side\n",
    "\n",
    "### Step-1\n",
    "\n",
    "The notebooks need to be executed with `mpirun`. This can be enabled with a custom Jupyter kernel. First one needs to unpack the content of [MPIpython3.zip](MPIpython3.zip) into appropriate directory:\n",
    "\n",
    "- Linux: `~/.local/share/jupyter/kernels`\n",
    "- Mac: `~/Library/Jupyter/kernels`\n",
    "- Windows: `%APPDATA%\\jupyter\\kernels`\n",
    "\n",
    "And then restart the Jupyter notebook.\n",
    "\n",
    "### Step-2.1\n",
    "\n",
    "Select the kernel `MPI Python 3` for the notebook: kernel -> Change kernel...\n",
    "\n",
    "Same for [Client.ipynb](Notebook-02-Client.ipynb).\n",
    "\n",
    "### Step-3.1\n",
    "\n",
    "Execute the following cell and after in [Client.ipynb](Notebook-02-Client.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "port = MPI.Open_port()\n",
    "open(\".port\", \"w\").write(port)\n",
    "\n",
    "comm = MPI.COMM_WORLD.Accept(port)\n",
    "MPI.Close_port(port)\n",
    "\n",
    "comm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-4\n",
    "\n",
    "Now the notebooks have been connected and you can proceed with the examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Hello\n",
    "\n",
    "Since we have built an `intercomm`, both processes have rank 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm.rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a normal situation, each process would have different rank. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest = 0\n",
    "comm.send(\"Hello from Server\", dest)\n",
    "comm.recv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Tag\n",
    "\n",
    "Tags can be used for identifying the messages. They must be `int`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm.send(\"message 1\", dest, tag=1)\n",
    "comm.send(\"message 2\", dest, tag=2)\n",
    "comm.send(\"message 3\", dest, tag=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Status\n",
    "\n",
    "The status collects information about the message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = MPI.Status()\n",
    "\n",
    "\n",
    "def print_status(s):\n",
    "    print(f\"Received message from {s.source} with tag {s.tag} and size {s.count}B\")\n",
    "\n",
    "\n",
    "print(comm.recv(status=status))\n",
    "print_status(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Array\n",
    "\n",
    "Arrays, like many other Python objects, can be easily sent via MPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.random.rand(10)\n",
    "comm.send(arr, 0)\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this is the \"slow\" way because the objects are pickled and much more data than needed is sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = comm.recv(status=status)\n",
    "print_status(status)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `Send` and `Recv`, instead only the array's content is sent. Here it is important though to previously allocate an array with the correct size and data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.zeros(1)\n",
    "comm.Recv(arr, status=status)\n",
    "print_status(status)\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Non-blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = comm.irecv()\n",
    "req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = req.wait()\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Matrix Vector product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider,\n",
    "$$A x = y,$$\n",
    "which can be split in domains as\n",
    "$$ \\left({\\begin{matrix}A_1&A_2\\\\A_3&A_4\\end{matrix}}\\right) \\left({\\begin{matrix}x_1\\\\x_2\\end{matrix}}\\right) = \\left({\\begin{matrix}A_1 x_1 + A_2 x_2\\\\A_3 x_1 + A_4 x_2\\end{matrix}}\\right) = \\left({\\begin{matrix}y_1\\\\y_2\\end{matrix}}\\right). $$\n",
    "\n",
    "In this example we keep the top part of matrix and vector on this notebook and the bottom part on the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "m1 = n // 2\n",
    "m2 = n - n // 2\n",
    "\n",
    "A = np.random.rand(m1, n)\n",
    "x1 = np.random.rand(m1)\n",
    "x2 = np.zeros(m2)\n",
    "\n",
    "comm.Send(x1, dest)\n",
    "comm.Recv(x2, dest)\n",
    "\n",
    "y = A[:, :m1].dot(x1) + A[:, m1:].dot(x2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm.Isend(x1, dest)\n",
    "req = comm.Irecv(x2, dest)\n",
    "\n",
    "y = A[:, :m1].dot(x1)\n",
    "\n",
    "req.wait()\n",
    "\n",
    "y += A[:, m1:].dot(x2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MPI Python 3",
   "language": "python",
   "name": "mpipython3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
